---
title: "Good times and better dates with R"
author: "Sami Rifai"
output:
  html_document:
    df_print: paged
---
## The international datetime standard in computing: *"YYYY-MM-DD HH:MM:SS"*  

## Some crucial packages for dealing with dates and times in R  
(1) lubridate - tidyverse friendly pakcage for parsing and arithmetic with date_time objects [lubridate vignette](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html)  
(2) hms - dealing with times [hms vignette]()  
(3) padr - [padr vignette](https://cran.r-project.org/web/packages/padr/vignettes/padr.html)  

```{r warning=FALSE, message=FALSE, eval=TRUE}
#opts_chunk$set(cache=TRUE, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE)
library(tidyverse);
library(lubridate);
library(hms); 
library(padr); 
```

### Parse a string to a date  
POSIXct is the datetime format for tidyverse packages.
lubridate::parse_date_time() can parse all kinds of date formats, but you have to specify the potential 'orders'.  
```{r}
x <- "1969-03-29"
x_parsed <- parse_date_time(x, "ymd")
print(x_parsed)
class(x_parsed)

as.POSIXct(x, tz="UTC")
as.POSIXct(100000, origin=Sys.time()) # here you can change the origin when creating the PosixCT object

x_vec <- c("1969-03-29", "2011-02-03", "2019-01-03")
as.POSIXct(x_vec, tz="UTC")

#piping ctrl+shift+m 
x_vec %>% as.POSIXct(., tz="UTZ")
```

### Dates often get converted to numerics  
For example, if you do a regression with a POSIXct variable, it will often be converted to seconds. Here is how to convert back: 
```{r}
tmp <- population %>% 
  mutate(datetime = parse_date_time(paste(year,1,1), 'ymd'))

fit_congo <- tmp %>% filter(country=="Congo") %>% lm(population~datetime, data=.)
fit_congo2 <- tmp %>% filter(country=="Congo") %>% lm(population~as.numeric(datetime), data=.)
coef(fit_congo); coef(fit_congo2); 

Sys.Date() %>% as.POSIXct() # convert Sys.Date to PosixCt
Sys.Date() %>% as.POSIXct() %>% as.numeric() # then to the numeric representation of PosixCt
Sys.Date() %>% as.POSIXct() %>% as.numeric() %>% as.POSIXct(., origin="1970-01-01") # then numeric back to PosixCt
```

## piping and pulling
```{r}
population
population %>% pull(year) #returns vector
population %>% select(year) #returns data frame with just the 'year' column
population %>% .$year # returns vector of the 'year' column 

congo_pop_vec <- population %>% filter(country=="Congo") %>% .$population
congo_year_vec <- population %>% filter(country=="Congo") %>% .$year
plot(congo_pop_vec~congo_year_vec)
```


```{r}
time <- ymd_hms("2010-12-13 15:30:30")
time
#> [1] "2010-12-13 15:30:30 UTC"

# Changes printing
with_tz(time, "America/Chicago")
#> [1] "2010-12-13 09:30:30 CST"

# Changes time
force_tz(time, "America/Chicago")
#> [1] "2010-12-13 15:30:30 CST"
```



Does the 29th of February exist? 
```{r}
x <- "2018-02-28"
x_parsed <- parse_date_time(x,"ymd"); 
print(x_parsed)

y <- "2018-02-29"
y_parsed <- parse_date_time(y,"ymd"); 
print(y_parsed)

```

## lubridate is clever enough to not permit dates that do not exist in the gregorian calendar  
```{r}
vec_dates <- c(as.character(Sys.Date()),"16-2-2018")
print(vec_dates); # mismatched formats in the same vector, oh no!
parse_date_time(vec_dates, orders = c("ymd","dmY"))
```

## Date and time arithmetic
```{r}
x <- Sys.time()
x_yesterday <- x - days(1)
print(x_yesterday)

x_yesterday + hours(24)

```


### hms has specific functions for working with times 
```{r}
library(hms)
hms(56, 34, 12)
#> 12:34:56
as.hms(1)
#> 00:00:01
as.hms("12:34:56")
#> 12:34:56
as.hms(Sys.time())
#> 16:45:12.828186
as.POSIXct(hms(1))
#> [1] "1970-01-01 00:00:01 UTC"

data.frame(hours = 1:3, hms = hms(hours = 1:3))
#>   hours      hms
#> 1     1 01:00:00
#> 2     2 02:00:00
#> 3     3 03:00:00
```


## DATE TIME INTERVALS! 
base::diff() is like your very efficient, but unreliable friend.
```{r}
ex1 <- c(Sys.time(), Sys.time()+days(5))
diff(ex1)

ex2 <- c(Sys.time(),Sys.time()+hours(5), Sys.time()+days(5))
diff(ex2)

# manually force diff to work on seconds and return days
(as.numeric(ex2) %>% diff())/(24*3600)


```

## But let's not give upon diff just yet.  
It is *very* fast for calculating datetime intervals, and much faster than the lubridate alternatives.
You can construct an alternative with Lubridate, but if you need to process 10s-100s of thousands 
of datetime intervals, diff() could make your code drastically faster. 
```{r}
library(microbenchmark)

# This function calculates difference between dates, returning the number of days
get_time_diffs <- function(date_vec){
  date_diff_vec <- numeric(length(date_vec)-1)
  for(i in 2:length(date_vec)){
    date_diff_vec[i-1] <- lubridate::int_length(lubridate::interval(date_vec[i-1], date_vec[i]))/86400
  }
  return(date_diff_vec);
} 



results_lubridate <- microbenchmark(
  get_time_diffs(ex2)
) %>% summary() %>% pull(median)

# Alternative: force dates to numeric
as.numeric(ex2) %>% as.POSIXct(origin="1970-01-01")

results_diff <- microbenchmark(
  {
   diff(ex2) 
  }
) %>% summary() %>% pull(median)

print(paste("Diff is", format(results_lubridate/results_diff, digits = 3), "x faster than my rolled lubridate function"))
```


### NEWEST OF THE NEW methods for dealing datetime intervals

```{r}
library(padr)
library(tidyverse)
coffee <- data.frame(
  time_stamp =  as.POSIXct(c(
    '2016-07-07 09:11:21', '2016-07-07 09:46:48',
    
    '2016-07-09 13:25:17',
    '2016-07-10 10:45:11'
  )),
  amount = c(3.14, 2.98, 4.11, 3.14)
)

coffee %>%
  thicken('day') %>%
  dplyr::group_by(time_stamp_day) %>%
  dplyr::summarise(day_amount = sum(amount)) %>%
  pad() %>%
  fill_by_value(day_amount, value = 0)

coffee %>%
  thicken('day') %>%
  dplyr::group_by(time_stamp_day) %>%
  dplyr::summarise(day_amount = sum(amount)) %>%
  pad() %>%
  fill_by_value(day_amount, value = 0)

# create a new column for "time_stamp_month"
coffee %>% 
  thicken('month') %>% 
  group_by(time_stamp_month)

```

### Putting it all together 
```{r}
library(tidyverse); library(lubridate); 

# temporal data
data(storms)

str(storms) # has the pieces, but not yet in POSIXct

storms %>% 
  filter(year>=1975 & year<=1980) %>% 
  mutate(datetime = parse_date_time(paste(year, month, day, hour), "ymd h")) %>% 
  arrange(datetime) %>% 
  thicken('month') %>% 
  group_by(datetime_month, lat, long) %>% 
  summarize(u_wind=mean(wind)) %>% 
  ggplot(data=., aes(datetime_month, lat, color=u_wind))+geom_point()+
  viridis::scale_color_viridis()

```

```{r}

```

